**Day0: [Lab2-0&1 Tokenization](https://colab.research.google.com/drive/1mGCQe-dGidYaLxXZbQ92RaxkI2WfiWKv?usp=sharing), [Lab2-2 LSTM](https://colab.research.google.com/drive/1B6sFWxloF93nmiTWOJkkp-unYIuDyScX?usp=sharing)**   
Today we will wrap up RNN discussions  
[BERT Preprocessing](https://www.tensorflow.org/text/guide/bert_preprocessing_guide)  
[Classifying text with BERT](https://www.tensorflow.org/text/tutorials/classify_text_with_bert)  

**Complete these readings/videos before next class**  
[Chapter 10.3 Convolutional Neural NetworkNetworks, ISLR2](https://hastie.su.domains/ISLR2/ISLRv2_website.pdf)  
[RNN with Keras](https://colab.research.google.com/github/tensorflow/docs/blob/snapshot-keras/site/en/guide/keras/rnn.ipynb)  
[Yann Lecun's MNIST site](http://yann.lecun.com/exdb/mnist/)  
[MNIST digit classification dataset by Keras](https://keras.io/api/datasets/mnist/)  
[Tensorflow2 quickstart for beginners](https://www.tensorflow.org/tutorials/quickstart/beginner)  

*Optional Fun Studd*
[Backpropagation & Optimization by CrashCourse AI](https://www.pbs.org/video/training-neural-networks-4-mq025r/)  

*Optional Readings*  
[Karpathy, A., Johnson, J., & Fei-Fei, L. (2015). Visualizing and understanding recurrent networks. arXiv preprint arXiv:1506.02078.](http://vision.stanford.edu/pdf/KarpathyICLR2016.pdf)  
[Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., ... & Polosukhin, I. (2017). Attention is all you need. Advances in neural information processing systems, 30.](https://arxiv.org/abs/1706.03762) 

**Day1: [CNN], [Lab2-3 MNIST101], [Lab2-4 MNIST with CNN]**  

**Complete these readings/videos before next class**  
[Dr. Chung's TF Keras CNN Model Template](https://docs.google.com/document/d/1gw1SanV6caqE4-iZAn3TO3tZ4poCYL3yvPZbidMqCxw/edit?usp=sharing)  

*Optional Fun Stuff*  
[Cats vs. Dogs? Lets Make an AI to Settle This by CrashCourse AI](https://www.pbs.org/video/cats-vs-dogs-lets-make-an-ai-to-settle-this-lab-19-rp1lwa/)  
