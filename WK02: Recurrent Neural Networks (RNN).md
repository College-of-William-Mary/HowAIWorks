**Day 0: [Model Configurations](https://www.dropbox.com/s/u0vsp3rcqi1zbhd/01-2%20Keras%20Mdel%20Configurations.pptx?dl=0)**  
6-7 minute team presentations of these topics  
Define and explain the key concepts - visualize as much you can! 
Explain the math equation(s)  
Demo some code snippet to illustrate key concepts  
Always reference the official documentation from Scikit-Learn or Tensorflow  
You can use other Internet sources but make sure they are consistent with the current official documentation  
If you send your presentation link to the instructor, it can be added to the list below.

Teams 1 & 12: sklearn.preprocessing - For numeric values and categorical values  
Teams 2 & 12: sklearn.impute  
[Team 3](https://www.dropbox.com/s/hjha10pov641lr1/AI%20Team%203%20Gradient%20Descent.pptx?dl=0) & 13: Optimizer - stochastic gradient descent  
[Team 4](https://github.com/shs7777/MSBA-Section-1-Team-4/blob/main/AI_Team4_adam.pptx) & 14: Optimizer - adam  
[Team 5](https://wmedu-my.sharepoint.com/:p:/g/personal/clwall_wm_edu/ETmfFK9ua_RPlwMPteGp7mUBxJ9yoOAxL3gxT1Cs4YGHFg?e=W7GxTb) & 15: Optimier - RMSprop  
Team 6 & 16: Classifier Loss/Metric - SparseCategoricalAccuracy  
[Team 7](https://www.dropbox.com/s/di3p36p5umjv310/Team%207%20Presentation.pptx?dl=0) & 17: Classifier Loss/Metric - SparseCategoricalCrossEntropy  
[Team 8](https://www.dropbox.com/s/1279n10xn6926ve/BinaryCrossEntropyPres.pdf?dl=0) & [Team 17](https://www.dropbox.com/s/mcwh1s6n9y809ob/AIpresentationTeam17.pptx?dl=0): Classifier Loss/Metric - BinaryCrossEntropy  
Team 9 & 18: Regressor Loss/Metric - Cosine_similarity  
[Team 10](https://www.dropbox.com/s/y5pllml4ioa33c4/AI_RegressorLoss_Huber%20Team%2010.pptx?dl=0) & 18: Regressor Loss/Metric - huber  
[Team 11](https://www.dropbox.com/s/syybp9a7sy2lbwe/Team%2011%20_%20Softmax.pptx?dl=0) & [Team 19](https://www.dropbox.com/s/0425bhpyx3ascza/TEAM19_Activation%20Functions.pptx?dl=0): Activation Function - softmax  

**Complete these readings/videos before next class**  
[Chapter 10.4 & 10.5 Recurrent Neural Networks, ISLR2](https://hastie.su.domains/ISLR2/ISLRv2_website.pdf)  
[Sparse Matrix Format in Tensorflow](https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor)  
[Masking & Padding in Keras](https://www.tensorflow.org/guide/keras/masking_and_padding#:~:text=Padding%20is%20a%20special%20form,pad%20or%20truncate%20some%20sequences.)  

*Optional References*  
[word2vec](https://code.google.com/archive/p/word2vec/)  
[GloVe](https://nlp.stanford.edu/projects/glove/)  
[Bag-of-N-Grams](https://colab.research.google.com/github/practical-nlp/practical-nlp/blob/master/Ch3/03_Bag_of_N_Grams.ipynb?authuser=0&pli=1)  

*Optional Fun Stuff*  
[Natural Language Processing by CrashCourse AI](https://www.pbs.org/video/natural-language-processing-7-eroyod/)  

**Day 1: [RNN](https://www.dropbox.com/s/nzja1j0ccd3wbr2/02-0%20RNN.pptx?dl=0)**  
[Keras Recurrent Layers](https://keras.io/api/layers/recurrent_layers/)  
[Keras Preprocessing Layers](https://keras.io/api/layers/preprocessing_layers/)  

**Day 2: [James Tucker](https://www.linkedin.com/in/james-m-tucker-7082251b0/) Guest Lecture**  
**Complete these readings/videos before next class**  
[Chapter 10.3 Convolutional Neural Networks, ISLR2](https://hastie.su.domains/ISLR2/ISLRv2_website.pdf)  
[Keras Convolutional Layers](https://keras.io/api/layers/convolution_layers/)  
[Keras Pooling Layers](https://keras.io/api/layers/convolution_layers/)  

*Optional Fun Stuff*  
[How to Make an AI Read Your Handwriting (LAB)](https://www.pbs.org/video/how-to-make-an-ai-read-your-handwriting-lab-5-oh9flk/)  
